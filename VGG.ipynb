{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrtdQ1/tBqkaBGRi/0WVnX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-94XIlv6x4Y",
        "outputId": "aa697c6b-6140-490c-d896-0ccfa79150e5"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=128)\n",
        "test_dataloader = DataLoader(test_data, batch_size=100)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZRtdU8mohe2"
      },
      "source": [
        "vgg_configs = {\n",
        "'A': [64,'P',128,'P',256,256,'P',512,512,'P',512,512,'P'],\n",
        "'B': [64,64,'P',128,128,'P',256,256,'P',512,512,'P',512,512,'P'],\n",
        "'C': [64,64,'P',128,128,'P',256,256,'conv1','P',512,512,'conv1','P',512,512,'conv1','P'],\n",
        "'D': [64,64,'P',128,128,'P',256,256,256,'P',512,512,512,'P',512,512,512,'P'],\n",
        "'E': [64,64,'P',128,128,'P',256,256,256,256,'P',512,512,512,512,'P',512,512,512,512,'P'],\n",
        "'F': [64,64,'P',128,128,'P',256,256,'P',512,512,512,512,512,'P'] #to test variations \n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super(VGG, self).__init__()\n",
        "        self.config = config\n",
        "        self.convs = self.stacklayers()\n",
        "        self.fullyconnected = nn.Sequential(nn.Linear(512,256),nn.ReLU(),nn.Dropout(),nn.Linear(256,256),nn.ReLU(),nn.Dropout(),nn.Linear(256,10))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = nn.Flatten()(x)\n",
        "        logits = self.fullyconnected(x)\n",
        "        return logits\n",
        "\n",
        "    def stacklayers(self):\n",
        "        res = []\n",
        "        prev = 3\n",
        "        for layer in vgg_configs[self.config]:\n",
        "            if layer == 'P':\n",
        "              res.append(nn.MaxPool2d(2,2))\n",
        "            elif layer == 'conv1':\n",
        "              res += [nn.Conv2d(prev,prev,1),nn.BatchNorm2d(prev),nn.ReLU()]\n",
        "            else:\n",
        "              res += [nn.Conv2d(prev,layer,3,padding='same'),nn.BatchNorm2d(layer),nn.ReLU()]\n",
        "              prev = layer\n",
        "        return nn.Sequential(*res)\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glbMYLJasxnI"
      },
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCwb1uB3fdrl",
        "outputId": "ecef41cb-9ecc-4a07-c995-efe162c165c0"
      },
      "source": [
        "learning_rate = 0.01\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model = VGG('E')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, weight_decay=5*0.0001)\n",
        "model = model.to(device)\n",
        "\n",
        "epochs = 50\n",
        "for t in range(epochs):\n",
        "    if t%10 == 0 and t != 0:\n",
        "      learning_rate = max(learning_rate/3.3,0.0001)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, weight_decay=5*0.0001)\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "    \n",
        "print(\"Done!\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.375035  [    0/50000]\n",
            "loss: 1.702620  [12800/50000]\n",
            "loss: 1.587500  [25600/50000]\n",
            "loss: 1.271972  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 56.4%, Avg loss: 1.249890 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.090797  [    0/50000]\n",
            "loss: 1.108820  [12800/50000]\n",
            "loss: 0.967657  [25600/50000]\n",
            "loss: 0.869436  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 68.5%, Avg loss: 0.965175 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.838702  [    0/50000]\n",
            "loss: 0.810136  [12800/50000]\n",
            "loss: 0.855137  [25600/50000]\n",
            "loss: 0.696152  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 72.4%, Avg loss: 0.865409 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.647445  [    0/50000]\n",
            "loss: 0.728626  [12800/50000]\n",
            "loss: 0.717536  [25600/50000]\n",
            "loss: 0.595837  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 74.9%, Avg loss: 0.791614 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.468625  [    0/50000]\n",
            "loss: 0.607054  [12800/50000]\n",
            "loss: 0.550023  [25600/50000]\n",
            "loss: 0.490074  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 77.2%, Avg loss: 0.730063 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.370593  [    0/50000]\n",
            "loss: 0.392634  [12800/50000]\n",
            "loss: 0.631662  [25600/50000]\n",
            "loss: 0.488410  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 0.717286 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.297024  [    0/50000]\n",
            "loss: 0.465381  [12800/50000]\n",
            "loss: 0.581342  [25600/50000]\n",
            "loss: 0.417147  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 0.712117 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.405013  [    0/50000]\n",
            "loss: 0.258417  [12800/50000]\n",
            "loss: 0.428832  [25600/50000]\n",
            "loss: 0.462186  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 79.8%, Avg loss: 0.675601 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.288448  [    0/50000]\n",
            "loss: 0.263776  [12800/50000]\n",
            "loss: 0.311036  [25600/50000]\n",
            "loss: 0.392757  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 80.0%, Avg loss: 0.707107 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.275142  [    0/50000]\n",
            "loss: 0.215433  [12800/50000]\n",
            "loss: 0.301685  [25600/50000]\n",
            "loss: 0.331731  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 81.0%, Avg loss: 0.693345 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.209278  [    0/50000]\n",
            "loss: 0.131263  [12800/50000]\n",
            "loss: 0.178546  [25600/50000]\n",
            "loss: 0.115600  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.638823 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.073714  [    0/50000]\n",
            "loss: 0.068619  [12800/50000]\n",
            "loss: 0.087291  [25600/50000]\n",
            "loss: 0.066081  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.748626 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.041810  [    0/50000]\n",
            "loss: 0.040139  [12800/50000]\n",
            "loss: 0.057279  [25600/50000]\n",
            "loss: 0.057565  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.815485 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.021290  [    0/50000]\n",
            "loss: 0.040469  [12800/50000]\n",
            "loss: 0.036431  [25600/50000]\n",
            "loss: 0.039087  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.851573 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.069487  [    0/50000]\n",
            "loss: 0.005774  [12800/50000]\n",
            "loss: 0.062677  [25600/50000]\n",
            "loss: 0.110925  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.885717 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.021925  [    0/50000]\n",
            "loss: 0.006095  [12800/50000]\n",
            "loss: 0.014274  [25600/50000]\n",
            "loss: 0.078559  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.894912 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.025172  [    0/50000]\n",
            "loss: 0.021936  [12800/50000]\n",
            "loss: 0.022597  [25600/50000]\n",
            "loss: 0.055801  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.927566 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.030560  [    0/50000]\n",
            "loss: 0.046858  [12800/50000]\n",
            "loss: 0.076336  [25600/50000]\n",
            "loss: 0.059767  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.917011 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.009490  [    0/50000]\n",
            "loss: 0.025363  [12800/50000]\n",
            "loss: 0.066082  [25600/50000]\n",
            "loss: 0.019370  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.914547 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.061917  [    0/50000]\n",
            "loss: 0.027106  [12800/50000]\n",
            "loss: 0.008600  [25600/50000]\n",
            "loss: 0.037594  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 84.2%, Avg loss: 0.925548 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.046321  [    0/50000]\n",
            "loss: 0.003008  [12800/50000]\n",
            "loss: 0.004424  [25600/50000]\n",
            "loss: 0.001079  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.3%, Avg loss: 0.875271 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.009511  [    0/50000]\n",
            "loss: 0.002021  [12800/50000]\n",
            "loss: 0.011878  [25600/50000]\n",
            "loss: 0.001518  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 0.887410 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.002452  [    0/50000]\n",
            "loss: 0.001621  [12800/50000]\n",
            "loss: 0.002196  [25600/50000]\n",
            "loss: 0.001558  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 0.901337 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.003020  [    0/50000]\n",
            "loss: 0.001812  [12800/50000]\n",
            "loss: 0.002401  [25600/50000]\n",
            "loss: 0.001243  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.908236 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.001494  [    0/50000]\n",
            "loss: 0.001104  [12800/50000]\n",
            "loss: 0.002285  [25600/50000]\n",
            "loss: 0.001332  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.947345 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.002419  [    0/50000]\n",
            "loss: 0.000858  [12800/50000]\n",
            "loss: 0.001033  [25600/50000]\n",
            "loss: 0.000522  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.4%, Avg loss: 0.961846 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.000595  [    0/50000]\n",
            "loss: 0.000531  [12800/50000]\n",
            "loss: 0.001185  [25600/50000]\n",
            "loss: 0.000427  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 0.953527 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.001953  [    0/50000]\n",
            "loss: 0.000675  [12800/50000]\n",
            "loss: 0.000788  [25600/50000]\n",
            "loss: 0.000635  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.4%, Avg loss: 0.964836 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.000781  [    0/50000]\n",
            "loss: 0.000843  [12800/50000]\n",
            "loss: 0.000989  [25600/50000]\n",
            "loss: 0.000917  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.983148 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.000560  [    0/50000]\n",
            "loss: 0.000502  [12800/50000]\n",
            "loss: 0.001893  [25600/50000]\n",
            "loss: 0.000633  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 0.989326 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.001463  [    0/50000]\n",
            "loss: 0.000536  [12800/50000]\n",
            "loss: 0.001044  [25600/50000]\n",
            "loss: 0.000617  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 0.994096 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.001663  [    0/50000]\n",
            "loss: 0.000450  [12800/50000]\n",
            "loss: 0.000917  [25600/50000]\n",
            "loss: 0.001091  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.3%, Avg loss: 0.990262 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.001207  [    0/50000]\n",
            "loss: 0.000809  [12800/50000]\n",
            "loss: 0.000577  [25600/50000]\n",
            "loss: 0.001708  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 0.983693 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.000492  [    0/50000]\n",
            "loss: 0.000653  [12800/50000]\n",
            "loss: 0.000668  [25600/50000]\n",
            "loss: 0.000198  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 1.004393 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.000484  [    0/50000]\n",
            "loss: 0.000945  [12800/50000]\n",
            "loss: 0.001018  [25600/50000]\n",
            "loss: 0.000634  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.993766 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.001152  [    0/50000]\n",
            "loss: 0.000376  [12800/50000]\n",
            "loss: 0.001489  [25600/50000]\n",
            "loss: 0.000261  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.4%, Avg loss: 0.995083 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.000793  [    0/50000]\n",
            "loss: 0.000876  [12800/50000]\n",
            "loss: 0.000690  [25600/50000]\n",
            "loss: 0.000636  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.992442 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.000432  [    0/50000]\n",
            "loss: 0.005096  [12800/50000]\n",
            "loss: 0.000772  [25600/50000]\n",
            "loss: 0.000298  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 0.988082 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.000798  [    0/50000]\n",
            "loss: 0.000437  [12800/50000]\n",
            "loss: 0.001236  [25600/50000]\n",
            "loss: 0.000748  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.4%, Avg loss: 1.005852 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.000515  [    0/50000]\n",
            "loss: 0.001201  [12800/50000]\n",
            "loss: 0.000976  [25600/50000]\n",
            "loss: 0.000915  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 1.003847 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.000758  [    0/50000]\n",
            "loss: 0.000269  [12800/50000]\n",
            "loss: 0.001780  [25600/50000]\n",
            "loss: 0.000329  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 1.012662 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.000303  [    0/50000]\n",
            "loss: 0.000594  [12800/50000]\n",
            "loss: 0.000815  [25600/50000]\n",
            "loss: 0.000272  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.4%, Avg loss: 0.999844 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.000947  [    0/50000]\n",
            "loss: 0.000503  [12800/50000]\n",
            "loss: 0.001071  [25600/50000]\n",
            "loss: 0.000943  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 1.008687 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.000991  [    0/50000]\n",
            "loss: 0.000656  [12800/50000]\n",
            "loss: 0.000765  [25600/50000]\n",
            "loss: 0.000277  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 1.008602 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.000423  [    0/50000]\n",
            "loss: 0.000997  [12800/50000]\n",
            "loss: 0.000606  [25600/50000]\n",
            "loss: 0.000282  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 1.007929 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.000678  [    0/50000]\n",
            "loss: 0.000412  [12800/50000]\n",
            "loss: 0.001328  [25600/50000]\n",
            "loss: 0.000486  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 1.000386 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.000889  [    0/50000]\n",
            "loss: 0.000987  [12800/50000]\n",
            "loss: 0.000811  [25600/50000]\n",
            "loss: 0.001221  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 1.025597 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.000306  [    0/50000]\n",
            "loss: 0.001027  [12800/50000]\n",
            "loss: 0.001066  [25600/50000]\n",
            "loss: 0.000574  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 1.001958 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.000616  [    0/50000]\n",
            "loss: 0.000359  [12800/50000]\n",
            "loss: 0.000939  [25600/50000]\n",
            "loss: 0.000234  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 0.999155 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.000630  [    0/50000]\n",
            "loss: 0.000562  [12800/50000]\n",
            "loss: 0.000618  [25600/50000]\n",
            "loss: 0.000685  [38400/50000]\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 1.027082 \n",
            "\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSfP8zDYjA2x"
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": []
    }
  ]
}